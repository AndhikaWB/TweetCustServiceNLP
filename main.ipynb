{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Customer Support Sentiment Analysis**\n",
    "- Code: [AndhikaWB](https://github.com/AndhikaWB/TweetCustServiceNLP)\n",
    "- Dataset: [Kaggle](https://www.kaggle.com/datasets/thoughtvector/customer-support-on-twitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Set Renderer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renderers configuration\n",
      "-----------------------\n",
      "    Default renderer: 'vscode'\n",
      "    Available renderers:\n",
      "        ['plotly_mimetype', 'jupyterlab', 'nteract', 'vscode',\n",
      "         'notebook', 'notebook_connected', 'kaggle', 'azure', 'colab',\n",
      "         'cocalc', 'databricks', 'json', 'png', 'jpeg', 'jpg', 'svg',\n",
      "         'pdf', 'browser', 'firefox', 'chrome', 'chromium', 'iframe',\n",
      "         'iframe_connected', 'sphinx_gallery', 'sphinx_gallery_png']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import plotly.io as io\n",
    "\n",
    "# Disable interactive visualization\n",
    "print(io.renderers)\n",
    "io.renderers.default = 'png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extract and Read Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Combine multi-part zip files\n",
    "with open('archive.zip', 'wb') as final_zip:\n",
    "    for zip_part in glob.glob('archive.zip.*'):\n",
    "        with open(zip_part, 'rb') as f:\n",
    "            shutil.copyfileobj(f, final_zip)\n",
    "\n",
    "# Extract the archive if it hasn't been extracted already\n",
    "if not os.path.isfile('data/twcs.csv'):\n",
    "    with zipfile.ZipFile('archive.zip') as zip:\n",
    "        zip.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811769</th>\n",
       "      <td>2987947</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Nov 22 08:43:51 +0000 2017</td>\n",
       "      <td>@823869 Hey, we'd be happy to look into this f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811770</th>\n",
       "      <td>2987948</td>\n",
       "      <td>823869</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Nov 22 08:35:16 +0000 2017</td>\n",
       "      <td>@115714 wtf!? I‚Äôve been having really shitty s...</td>\n",
       "      <td>2987947</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811771</th>\n",
       "      <td>2812240</td>\n",
       "      <td>121673</td>\n",
       "      <td>True</td>\n",
       "      <td>Thu Nov 23 04:13:07 +0000 2017</td>\n",
       "      <td>@143549 @sprintcare You have to go to https://...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2812239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811772</th>\n",
       "      <td>2987949</td>\n",
       "      <td>AldiUK</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Nov 22 08:31:24 +0000 2017</td>\n",
       "      <td>@823870 Sounds delicious, Sarah! üòã https://t.c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811773</th>\n",
       "      <td>2987950</td>\n",
       "      <td>823870</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Nov 21 22:01:04 +0000 2017</td>\n",
       "      <td>@AldiUK  warm sloe gin mince pies with ice cre...</td>\n",
       "      <td>2987951,2987949</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2811774 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id   author_id  inbound                      created_at  \\\n",
       "0               1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1               2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2               3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3               4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4               5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "...           ...         ...      ...                             ...   \n",
       "2811769   2987947  sprintcare    False  Wed Nov 22 08:43:51 +0000 2017   \n",
       "2811770   2987948      823869     True  Wed Nov 22 08:35:16 +0000 2017   \n",
       "2811771   2812240      121673     True  Thu Nov 23 04:13:07 +0000 2017   \n",
       "2811772   2987949      AldiUK    False  Wed Nov 22 08:31:24 +0000 2017   \n",
       "2811773   2987950      823870     True  Tue Nov 21 22:01:04 +0000 2017   \n",
       "\n",
       "                                                      text response_tweet_id  \\\n",
       "0        @115712 I understand. I would like to assist y...                 2   \n",
       "1            @sprintcare and how do you propose we do that               NaN   \n",
       "2        @sprintcare I have sent several private messag...                 1   \n",
       "3        @115712 Please send us a Private Message so th...                 3   \n",
       "4                                       @sprintcare I did.                 4   \n",
       "...                                                    ...               ...   \n",
       "2811769  @823869 Hey, we'd be happy to look into this f...               NaN   \n",
       "2811770  @115714 wtf!? I‚Äôve been having really shitty s...           2987947   \n",
       "2811771  @143549 @sprintcare You have to go to https://...               NaN   \n",
       "2811772  @823870 Sounds delicious, Sarah! üòã https://t.c...               NaN   \n",
       "2811773  @AldiUK  warm sloe gin mince pies with ice cre...   2987951,2987949   \n",
       "\n",
       "         in_response_to_tweet_id  \n",
       "0                            3.0  \n",
       "1                            1.0  \n",
       "2                            4.0  \n",
       "3                            5.0  \n",
       "4                            6.0  \n",
       "...                          ...  \n",
       "2811769                2987948.0  \n",
       "2811770                      NaN  \n",
       "2811771                2812239.0  \n",
       "2811772                2987950.0  \n",
       "2811773                      NaN  \n",
       "\n",
       "[2811774 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/twcs.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`inbound` here means whether it's directed to a company's customer support or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data/Text Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data Type Correction**\n",
    "For possible Exploratory Data Analysis (EDA) at the end\n",
    "- String to datetime (`created_at`)\n",
    "- String to integer array (`response_tweet_id`)\n",
    "- Float to integer (other tweet IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2811774 entries, 0 to 2811773\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count    Dtype  \n",
      "---  ------                   --------------    -----  \n",
      " 0   tweet_id                 2811774 non-null  int64  \n",
      " 1   author_id                2811774 non-null  object \n",
      " 2   inbound                  2811774 non-null  bool   \n",
      " 3   created_at               2811774 non-null  object \n",
      " 4   text                     2811774 non-null  object \n",
      " 5   response_tweet_id        1771145 non-null  object \n",
      " 6   in_response_to_tweet_id  2017439 non-null  float64\n",
      "dtypes: bool(1), float64(1), int64(1), object(4)\n",
      "memory usage: 131.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check data types and memory usage\n",
    "df.info(show_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:46:24 +0000 2017</td>\n",
       "      <td>@115712 Can you please send us a private messa...</td>\n",
       "      <td>5,7</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>115713</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:04:47 +0000 2017</td>\n",
       "      <td>@sprintcare You gonna magically change your co...</td>\n",
       "      <td>11,13,14</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21</td>\n",
       "      <td>Ask_Spectrum</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:14:37 +0000 2017</td>\n",
       "      <td>@115716 What information is incorrect? ^JK</td>\n",
       "      <td>22,23</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>66</td>\n",
       "      <td>115728</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:03:38 +0000 2017</td>\n",
       "      <td>@ChipotleTweets @28 \\nI don't fit in my Veggie...</td>\n",
       "      <td>64,67</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id     author_id  inbound                      created_at  \\\n",
       "5          6    sprintcare    False  Tue Oct 31 21:46:24 +0000 2017   \n",
       "6          8        115712     True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "8         12        115713     True  Tue Oct 31 22:04:47 +0000 2017   \n",
       "15        21  Ask_Spectrum    False  Tue Oct 31 22:14:37 +0000 2017   \n",
       "60        66        115728     True  Tue Oct 31 22:03:38 +0000 2017   \n",
       "\n",
       "                                                 text response_tweet_id  \\\n",
       "5   @115712 Can you please send us a private messa...               5,7   \n",
       "6           @sprintcare is the worst customer service            9,6,10   \n",
       "8   @sprintcare You gonna magically change your co...          11,13,14   \n",
       "15         @115716 What information is incorrect? ^JK             22,23   \n",
       "60  @ChipotleTweets @28 \\nI don't fit in my Veggie...             64,67   \n",
       "\n",
       "    in_response_to_tweet_id  \n",
       "5                       8.0  \n",
       "6                       NaN  \n",
       "8                      15.0  \n",
       "15                     24.0  \n",
       "60                      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see why \"response_tweet_id\" is an object, not int/float\n",
    "df[df['response_tweet_id'].notna() & df['response_tweet_id'].str.contains(',')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that `response_tweet_id` is a list (array), so we need to parse it correctly before fixing the data type. However, note that the `response_tweet_id` value can also be nan (float)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def tweet_id_to_arr(value):\n",
    "    # If empty/nan (aka the first tweet) then no need to make it as an array\n",
    "    if type(value) == float and math.isnan(value): return pd.NA\n",
    "    # Numpy's int array doesn't support nan, while Pandas' array does\n",
    "    # However, converting to Pandas' array can be a lot slower\n",
    "    return np.array(value.split(','), dtype = np.int64)\n",
    "\n",
    "df['response_tweet_id'] = df['response_tweet_id'].apply(tweet_id_to_arr)\n",
    "\n",
    "# https://strftime.org/\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], format = '%a %b %d %H:%M:%S %z %Y')\n",
    "\n",
    "# Convert float to Pandas' Int64 (support nan)\n",
    "# Pandas' Int64 array will use \"pd.NA\" rather than \"np.nan\"\n",
    "# https://pandas.pydata.org/docs/user_guide/integer_na.html\n",
    "cols = ['tweet_id', 'in_response_to_tweet_id']\n",
    "df[cols] = df[cols].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "<class 'pandas._libs.missing.NAType'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'pandas._libs.missing.NAType'>\n"
     ]
    }
   ],
   "source": [
    "# Check whether Numpy's array and Pandas' array and use the same data type\n",
    "print(type(df['response_tweet_id'].iloc[0][0])) # value row\n",
    "print(type(df['response_tweet_id'].iloc[1])) # nan row\n",
    "\n",
    "print(type(df['in_response_to_tweet_id'].iloc[0])) # value row\n",
    "print(type(df['in_response_to_tweet_id'].iloc[6])) # nan row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2811774 entries, 0 to 2811773\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count    Dtype              \n",
      "---  ------                   --------------    -----              \n",
      " 0   tweet_id                 2811774 non-null  Int64              \n",
      " 1   author_id                2811774 non-null  object             \n",
      " 2   inbound                  2811774 non-null  bool               \n",
      " 3   created_at               2811774 non-null  datetime64[ns, UTC]\n",
      " 4   text                     2811774 non-null  object             \n",
      " 5   response_tweet_id        1771145 non-null  object             \n",
      " 6   in_response_to_tweet_id  2017439 non-null  Int64              \n",
      "dtypes: Int64(2), bool(1), datetime64[ns, UTC](1), object(3)\n",
      "memory usage: 136.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(show_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Basic Text Preprocessing (1)**\n",
    "Before moving on to sentiment analysis, we need to do some text preprocessing first. However, not everything has to be preprocessed/cleaned before doing the analysis. Some sentiment analysis libraries (e.g. [VADER](https://github.com/cjhutto/vaderSentiment)) are able to process raw text or even make a better prediction compared to cleaned text, so we only need to:\n",
    "- Remove non-English tweets\n",
    "- Remove URLs\n",
    "- Remove HTML tags ([entities](https://www.w3schools.com/html/html_entities.asp) currently won't be checked, e.g. `%20`, `&nbsp`)\n",
    "- Remove emails (must be prioritized before mentions)\n",
    "- Remove mentions and hashtags\n",
    "- Remove phone numbers (it's easier to just remove all numbers, but might mess with slang words or emoticons)\n",
    "- Replace repeated characters (3 times+)\n",
    "- Replace non-standard or multiple whitespaces (can be done last)\n",
    "\n",
    "Depending on the libraries/algorithms, we may also need to do:\n",
    "- Slang words and idioms conversion (to a more common words)\n",
    "- Emojis and emoticons removal (or describe it as words)\n",
    "\n",
    "**Note:** Be aware that some (if not most) sentiment analysis libraries are only able to score 1-gram word. [Splitting or describing](https://www.kaggle.com/code/sudalairajkumar/getting-started-with-text-preprocessing) emojis/emoticons/slang as multiple words can also drastically [affect the score](https://medium.com/analytics-vidhya/sentiment-analysis-with-nltk-textblob-and-flair-a321d1460867) (e.g. \"happy smile\" will likely have more positive score than just \"happy\" or \"smile\").\n",
    "\n",
    "See more info about VADER on the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ja\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# fastText is a NLP library made by Facebook\n",
    "# https://github.com/facebookresearch/fastText\n",
    "import fasttext\n",
    "# Regex\n",
    "import re\n",
    "\n",
    "# Suppress warning on fastText v0.9.2\n",
    "fasttext.FastText.eprint = lambda x: None\n",
    "\n",
    "# Predict language to remove non-English tweets\n",
    "# https://fasttext.cc/docs/en/language-identification.html\n",
    "lang_detector = fasttext.load_model('misc/fastText/lid.176.ftz')\n",
    "\n",
    "def lang_predict(value: str):\n",
    "    # Replace newline and possibly other unsupported whitespace characters\n",
    "    # The model will complain since it thinks each newline might have a different language\n",
    "    value = re.sub(r'\\s+', ' ', value)\n",
    "    # Will return nested tuple (each contains the language code and probability)\n",
    "    result = lang_detector.predict(value)\n",
    "    # ISO-639-1 or ISO-639-2\n",
    "    lang_code = result[0][0].split('__label__')[1]\n",
    "    return lang_code\n",
    "\n",
    "def is_english(value: str):\n",
    "    return lang_predict(value) == 'en'\n",
    "\n",
    "# Check whether fastText can handle non-ASCII text or not\n",
    "# Since there are also non-English tweets (e.g. Japanese)\n",
    "text = '„Åì„Çì„Å´„Å°„ÅØ üòä'\n",
    "print(lang_predict(text))\n",
    "print(is_english(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before non-English language removal: 2811774\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462a5b0c4f544652bb8c25e5315ba1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2811774 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After non-English language removal: 2674836\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 22:10:47+00:00</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:11:45+00:00</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:08:27+00:00</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 21:54:49+00:00</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 21:49:35+00:00</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>[4]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                created_at  \\\n",
       "0         1  sprintcare    False 2017-10-31 22:10:47+00:00   \n",
       "1         2      115712     True 2017-10-31 22:11:45+00:00   \n",
       "2         3      115712     True 2017-10-31 22:08:27+00:00   \n",
       "3         4  sprintcare    False 2017-10-31 21:54:49+00:00   \n",
       "4         5      115712     True 2017-10-31 21:49:35+00:00   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...               [2]   \n",
       "1      @sprintcare and how do you propose we do that              <NA>   \n",
       "2  @sprintcare I have sent several private messag...               [1]   \n",
       "3  @115712 Please send us a Private Message so th...               [3]   \n",
       "4                                 @sprintcare I did.               [4]   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                        3  \n",
       "1                        1  \n",
       "2                        4  \n",
       "3                        5  \n",
       "4                        6  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import swifter\n",
    "\n",
    "# Pandas' \"apply\" function is not very efficient and may only use single core\n",
    "# https://stackoverflow.com/questions/45545110/make-pandas-dataframe-apply-use-all-cores\n",
    "# https://github.com/jmcarpenter2/swifter/blob/master/docs/documentation.md\n",
    "swifter.set_defaults(allow_dask_on_strings = True, force_parallel = True)\n",
    "\n",
    "print(f'Before non-English language removal: {len(df)}')\n",
    "\n",
    "# Now remove the non-English languages from the dataset (1-3 minutes)\n",
    "df['text'] = df['text'].swifter.apply(lambda x: x if is_english(x) else pd.NA)\n",
    "df.dropna(subset = ['text'], inplace = True)\n",
    "\n",
    "print(f'After non-English language removal: {len(df)}')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi @user_name please contact us at aaa@aaa.com or +1 (234) 567-890 #Support\n",
      "Hi please contact us at or \n"
     ]
    }
   ],
   "source": [
    "def preproc_useless_info(value: str):\n",
    "    # Compile regex or not?\n",
    "    # https://stackoverflow.com/questions/452104/is-it-worth-using-pythons-re-compile\n",
    "\n",
    "    # Remove URLs\n",
    "    value = re.sub(r'https?://\\S+|www\\.\\S+', ' ', value)\n",
    "    # Remove HTML tags\n",
    "    value = re.sub(r'<.*?>', ' ', value)\n",
    "    # Remove emails (underscore is already included as part of \"\\w\")\n",
    "    value = re.sub(r'[\\w\\.\\-]+@[\\w\\.]+', ' ', value)\n",
    "    # Remove mentions and hashtags\n",
    "    value = re.sub(r'[@|#]\\w+', ' ', value)\n",
    "    # Remove phone numbers\n",
    "    # +12345678, +1 234-5678, +1 (234) 5678, etc\n",
    "    # https://uibakery.io/regex-library/phone-number-python\n",
    "    phone_re = r'\\+?\\d{1,4}?[-.\\s]?\\(?\\d{1,3}?\\)?[-.\\s]?\\d{1,4}[-.\\s]?\\d{1,4}[-.\\s]?\\d{1,9}'\n",
    "    value = re.sub(phone_re, ' ', value)\n",
    "    # Replace repeating characters 3 times+ (e.g. buuut -> but)\n",
    "    value = re.sub(r'(\\w)(\\1{2,})', r'\\1', value)\n",
    "    # FIXME Replace repeating words/emojis 2 times+ (e.g. very very bad, ü§Æü§Æü§Æ)\n",
    "    # value = re.sub(r'\\b(\\w+)\\s+\\1\\b', r'\\1', value)\n",
    "\n",
    "    # Replace non-standard or multiple whitespaces with a normal space\n",
    "    value = re.sub(r'\\s+', ' ', value)\n",
    "\n",
    "    return value\n",
    "\n",
    "# Test the preprocessing function\n",
    "text = 'Hi @user_name please contact us at aaa@aaa.com or +1 (234) 567-890 #Support'\n",
    "print(text)\n",
    "print(preproc_useless_info(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e500927120240c9918fee87418bf54c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2674836 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 22:10:47+00:00</td>\n",
       "      <td>I understand. I would like to assist you. We ...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:11:45+00:00</td>\n",
       "      <td>and how do you propose we do that</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:08:27+00:00</td>\n",
       "      <td>I have sent several private messages and no o...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 21:54:49+00:00</td>\n",
       "      <td>Please send us a Private Message so that we c...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 21:49:35+00:00</td>\n",
       "      <td>I did.</td>\n",
       "      <td>[4]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                created_at  \\\n",
       "0         1  sprintcare    False 2017-10-31 22:10:47+00:00   \n",
       "1         2      115712     True 2017-10-31 22:11:45+00:00   \n",
       "2         3      115712     True 2017-10-31 22:08:27+00:00   \n",
       "3         4  sprintcare    False 2017-10-31 21:54:49+00:00   \n",
       "4         5      115712     True 2017-10-31 21:49:35+00:00   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0   I understand. I would like to assist you. We ...               [2]   \n",
       "1                  and how do you propose we do that              <NA>   \n",
       "2   I have sent several private messages and no o...               [1]   \n",
       "3   Please send us a Private Message so that we c...               [3]   \n",
       "4                                             I did.               [4]   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                        3  \n",
       "1                        1  \n",
       "2                        4  \n",
       "3                        5  \n",
       "4                        6  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the dataset for sentiment analysis (1-2 minutes)\n",
    "df['text'] = df['text'].swifter.apply(preproc_useless_info)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Sentiment Analysis**\n",
    "I'm going to use VADER ([standalone](https://github.com/cjhutto/vaderSentiment) | [NLTK](https://www.nltk.org/_modules/nltk/sentiment/vader.html)) as the sentiment analysis library. Based on the docs, VADER has/can detect:\n",
    "- 7520 [vocabulary](https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt) (includes emoticons) and 3570 [emojis](https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/emoji_utf8_lexicon.txt)\n",
    "- Negation and contrasted negation: `not good`, `wasn't very good`\n",
    "- Upper case and punctuation: `I'M ANGRY!!!`\n",
    "- Slang words: `kinda`, `lol`, `sux`, etc\n",
    "- Emojis and emoticons: `:)`, üòÅ, üíò, etc\n",
    "\n",
    "Obviously, there are also other sentiment analysis algorithms, but VADER seems to be the best for now, with a few [issues](https://github.com/cjhutto/vaderSentiment/issues):\n",
    "- Can't detect irony/satire/sarcasm (like all other alternatives)\n",
    "- Can only work accurately on English language\n",
    "- May not be able to detect N-gram words and idioms (fed up, piece of cake, etc), though it still work with negated/intensified word like `not`, `very`, etc\n",
    "- Most likely not all slang words and emojis/emoticons are covered (especially all that are newer than VADER itself)\n",
    "- When using VADER via NLTK, emojis won't be checked, it is probably using the outdated VADER version\n",
    "\n",
    "VADER alternatives (comparison [[1](https://www.researchgate.net/publication/343473213)] [[2](https://towardsdatascience.com/ab561f834f89)] [[3](https://towardsdatascience.com/the-best-python-sentiment-analysis-package-1-huge-common-mistake-d6da9ad6cdeb)] [[4](https://medium.com/analytics-vidhya/sentiment-analysis-with-nltk-textblob-and-flair-a321d1460867)] [[5](https://www.kaggle.com/discussions/questions-and-answers/231701)]):\n",
    "- AFINN\n",
    "- SentiWordNet\n",
    "- TextBlob\n",
    "- FLAIR (good alternative)\n",
    "- fastText (need model)\n",
    "- Naive Bayes\n",
    "- RNN/LSTM/GRU (which we are gonna do later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the \"misc\" folder to look up for NLTK data\n",
    "# Doesn't always work, may be hardcoded somewhere\n",
    "os.environ['NLTK_DATA'] = os.path.abspath('misc')\n",
    "\n",
    "import nltk\n",
    "nltk.data.path.append(os.path.abspath('misc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 0\n",
      "Neutral: 1\n",
      "Negative: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import nltk.sentiment.vader as vader\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "\n",
    "try:\n",
    "    # Load the pre-downloaded vocabulary (v3.3.2), for NLTK\n",
    "    sia = vader.SentimentIntensityAnalyzer('misc/sentiment/vader_lexicon.txt')\n",
    "except:\n",
    "    # Load the default vocabulary\n",
    "    sia = vader.SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_sentiment(value: str, class_mode = 'binary'):\n",
    "    # https://github.com/cjhutto/vaderSentiment#about-the-scoring\n",
    "    scores = sia.polarity_scores(value)\n",
    "\n",
    "    if class_mode == 'label':\n",
    "        if scores['compound'] >= 0.5: return 'Positive'\n",
    "        elif scores['compound'] <= -0.5: return 'Negative'\n",
    "        return 'Neutral'\n",
    "    elif class_mode == 'binary':\n",
    "        if scores['compound'] >= 0.5: return 0\n",
    "        elif scores['compound'] <= -0.5: return 2\n",
    "        return 1\n",
    "    elif class_mode == 'one_hot':\n",
    "        if scores['compound'] >= 0.5: return np.array([1, 0, 0])\n",
    "        elif scores['compound'] <= -0.5: return np.array([0, 0, 1])\n",
    "        return np.array([0, 1, 0])\n",
    "\n",
    "# Test the sentiment analysis\n",
    "# Note that NLTK's VADER doesn't support emojis (use standalone VADER instead)\n",
    "print('Positive:', vader_sentiment('It is ok üòÅ'))\n",
    "print('Neutral:', vader_sentiment('Your customer service is so-so'))\n",
    "print('Negative:', vader_sentiment('The service is NOT GOOD at all!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08101bf4ce6c4452a8e10c7820a2a8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2674836 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 22:10:47+00:00</td>\n",
       "      <td>I understand. I would like to assist you. We ...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:11:45+00:00</td>\n",
       "      <td>and how do you propose we do that</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:08:27+00:00</td>\n",
       "      <td>I have sent several private messages and no o...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 21:54:49+00:00</td>\n",
       "      <td>Please send us a Private Message so that we c...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 21:49:35+00:00</td>\n",
       "      <td>I did.</td>\n",
       "      <td>[4]</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                created_at  \\\n",
       "0         1  sprintcare    False 2017-10-31 22:10:47+00:00   \n",
       "1         2      115712     True 2017-10-31 22:11:45+00:00   \n",
       "2         3      115712     True 2017-10-31 22:08:27+00:00   \n",
       "3         4  sprintcare    False 2017-10-31 21:54:49+00:00   \n",
       "4         5      115712     True 2017-10-31 21:49:35+00:00   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0   I understand. I would like to assist you. We ...               [2]   \n",
       "1                  and how do you propose we do that              <NA>   \n",
       "2   I have sent several private messages and no o...               [1]   \n",
       "3   Please send us a Private Message so that we c...               [3]   \n",
       "4                                             I did.               [4]   \n",
       "\n",
       "   in_response_to_tweet_id  label  \n",
       "0                        3      0  \n",
       "1                        1      1  \n",
       "2                        4      1  \n",
       "3                        5      1  \n",
       "4                        6      1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze tweets sentiment analysis (2-4 minute)\n",
    "df['label'] = df['text'].swifter.apply(vader_sentiment)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(\n",
    "    go.Bar(\n",
    "        x = ['Positive', 'Neutral', 'Negative'],\n",
    "        # Binary label\n",
    "        y = df['label'].value_counts().sort_index()\n",
    "        # One hot label\n",
    "        # y = np.sum(df['label'].values)\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(title_text = 'Tweet Sentiment Distribution')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is not balanced, we need to apply either downsampling and/or upsampling (augmentation) after this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Tweet Augmentation**\n",
    "As you can see from the earlier graph, the tweet distribution is not balanced, so we need to augment some tweets to increase the data (especially the minority class). There are a few ready-made libraries we can use:\n",
    "- `nlpaug`: Slower, but provide more authentic data (synonym/antonym, insert new word, etc)\n",
    "- `imblearn`: Faster, but the augmented word may not represent real data (vector level augmentation, e.g. SMOTE)\n",
    "\n",
    "Note that augmentation is a form of oversampling, since the data is already huge, we can also apply undersampling at the end of this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Your service is trully the worst!\n",
      "Synonym: Your robert william service is trully the big!\n",
      "Antonym: Your service is trully the unregretful!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nlpaug.augmenter.word as naw\n",
    "import multiprocessing as mp\n",
    "\n",
    "try:\n",
    "    # Import the stopwords list\n",
    "    # Very important, especially for antonym augmentation\n",
    "    # Words like not, very, etc may have opposite effect if not ignored\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Don't reinitialize the augmenter on every function call\n",
    "# \"aug_p\" is the percentage of words to be augmented\n",
    "# \"stopwords\" will ignore specified words, but doesn't replace/remove them\n",
    "aug_ant = naw.AntonymAug(aug_p = 0.8, stopwords = stop_words)\n",
    "aug_syn = naw.SynonymAug(aug_src = 'wordnet', aug_p = 0.6, stopwords = stop_words)\n",
    "\n",
    "# Replace words in a sentence with their synonym or antonym\n",
    "# https://github.com/makcedward/nlpaug/blob/master/example/textual_augmenter.ipynb\n",
    "def preproc_augment(value: str, synonym = True):\n",
    "    if synonym:\n",
    "        # Augment will return a list, even if there is only 1 output\n",
    "        value = aug_syn.augment(value, num_thread = mp.cpu_count())[0]\n",
    "    else:\n",
    "        # Note that for antonym, the augmenter doesn't replace emojis with their inverse variants\n",
    "        # So we will need to remove emojis (and/or emoticons) after applying the antonym\n",
    "        # https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python/\n",
    "        value = aug_ant.augment(value, num_thread = mp.cpu_count())[0]\n",
    "        value = value.encode('latin-1', 'ignore').decode('latin-1')\n",
    "\n",
    "    return value\n",
    "\n",
    "text = 'Your service is trully the worst!'\n",
    "print('Original:', text)\n",
    "\n",
    "print('Synonym:', preproc_augment(text))\n",
    "print('Antonym:', preproc_augment(text, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on my observation, `nlpaug`'s built-in tokenizer will not lowercase words, it only use regex `\\w` (alphabet + digit) match and then split it (check the `WordAugmenter` source code to see it).\n",
    "\n",
    "If there is a stopword in a sentence that contains mixed/upper case (e.g. `It`, `IT`), it will still be processed (not ignored). In this case, the word may be replaced with `information technology` (which is wrong if the original sentence is `IT IS BAD!!!`). The side effect is not that severe in the case of sentiment analysis, but still need caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_equal(label, df):\n",
    "    # The usual Pandas value query won't work if the data type is an array\n",
    "    # It will assign the array to replace the whole column instead\n",
    "\n",
    "    # Workaround to filter tweets belonging to a certain \"label\" (one hot array)\n",
    "    # \"label\" is either positive (100), neutral (010), or negative (001)\n",
    "    return df['label'].apply(lambda x:\n",
    "        # One hot label\n",
    "        np.array_equal(x, label)\n",
    "        if type(x) == np.ndarray\n",
    "        # Binary label\n",
    "        else x == np.argmax(label)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "      <th>label</th>\n",
       "      <th>augmented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 21:45:10</td>\n",
       "      <td>is the bad client military service</td>\n",
       "      <td>[ 9  6 10]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 22:10:35</td>\n",
       "      <td>This is sadden to take heed. Please sprout ame...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>115713</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:04:47</td>\n",
       "      <td>You gonna as if by magic convert your connecti...</td>\n",
       "      <td>[11 13 14]</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>115719</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:10:46</td>\n",
       "      <td>mortal from please assist me üò© üò© üò© üò© 1 ' m hav...</td>\n",
       "      <td>[34]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>115723</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 19:58:22</td>\n",
       "      <td>Cut out every xx second this is derisory</td>\n",
       "      <td>[56]</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound           created_at  \\\n",
       "0         8      115712     True  2017-10-31 21:45:10   \n",
       "1        11  sprintcare    False  2017-10-31 22:10:35   \n",
       "2        12      115713     True  2017-10-31 22:04:47   \n",
       "3        36      115719     True  2017-10-31 22:10:46   \n",
       "4        57      115723     True  2017-10-31 19:58:22   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0                 is the bad client military service        [ 9  6 10]   \n",
       "1  This is sadden to take heed. Please sprout ame...               NaN   \n",
       "2  You gonna as if by magic convert your connecti...        [11 13 14]   \n",
       "3  mortal from please assist me üò© üò© üò© üò© 1 ' m hav...              [34]   \n",
       "4           Cut out every xx second this is derisory              [56]   \n",
       "\n",
       "   in_response_to_tweet_id  label  augmented  \n",
       "0                      NaN      2       True  \n",
       "1                     12.0      2       True  \n",
       "2                     15.0      2       True  \n",
       "3                      NaN      2       True  \n",
       "4                     58.0      2       True  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mark all members of the original dataframe as real data (not augmented)\n",
    "df['augmented'] = False\n",
    "\n",
    "if os.path.isfile('data/df_neg_1.csv'):\n",
    "    # Load the saved augmented data if available\n",
    "    df_neg_1 = pd.read_csv('data/df_neg_1.csv')\n",
    "else:\n",
    "    # Apply synonym augmentation to negative tweets (20-23 minutes)\n",
    "    df_neg_1 = df[ label_equal(np.array([0, 0, 1]), df) ]\n",
    "    df_neg_1['text'] = df_neg_1['text'].swifter.apply(preproc_augment)\n",
    "    # Mark the augmented data\n",
    "    df_neg_1['augmented'] = True\n",
    "\n",
    "print(len(df_neg_1))\n",
    "df_neg_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Negative tweets (combined with the original) after the previous augmentation should be around 468k (234k * 2)\n",
    "- It's still less than the positive tweets count (730k), so we need more augmentation (apply antonym to positive tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filter: 30208\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "      <th>label</th>\n",
       "      <th>augmented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159</td>\n",
       "      <td>115736</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:00:10</td>\n",
       "      <td>Btw starve out $ 3 burritos if you undress up ...</td>\n",
       "      <td>[158]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316</td>\n",
       "      <td>115785</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-01 01:13:10</td>\n",
       "      <td>Kinda obviate to unmake uncertain I have 680 $...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>311</td>\n",
       "      <td>115785</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 20:04:15</td>\n",
       "      <td>Would dislike to ignore so I can break uncerta...</td>\n",
       "      <td>[309]</td>\n",
       "      <td>318.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>337</td>\n",
       "      <td>115797</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-09 20:15:48</td>\n",
       "      <td>Hi! i would dislike to ignore on my itenerary ...</td>\n",
       "      <td>[338]</td>\n",
       "      <td>335.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369</td>\n",
       "      <td>115800</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 14:25:55</td>\n",
       "      <td>You ' ll be even unhappy to ignore that the re...</td>\n",
       "      <td>[368 370]</td>\n",
       "      <td>371.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id author_id  inbound           created_at  \\\n",
       "0       159    115736     True  2017-10-31 22:00:10   \n",
       "1       316    115785     True  2017-11-01 01:13:10   \n",
       "2       311    115785     True  2017-10-31 20:04:15   \n",
       "3       337    115797     True  2017-11-09 20:15:48   \n",
       "4       369    115800     True  2017-10-31 14:25:55   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  Btw starve out $ 3 burritos if you undress up ...             [158]   \n",
       "1  Kinda obviate to unmake uncertain I have 680 $...               NaN   \n",
       "2  Would dislike to ignore so I can break uncerta...             [309]   \n",
       "3  Hi! i would dislike to ignore on my itenerary ...             [338]   \n",
       "4  You ' ll be even unhappy to ignore that the re...         [368 370]   \n",
       "\n",
       "   in_response_to_tweet_id  label  augmented  \n",
       "0                      NaN      2       True  \n",
       "1                    315.0      2       True  \n",
       "2                    318.0      2       True  \n",
       "3                    335.0      2       True  \n",
       "4                    371.0      2       True  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile('data/df_neg_2.csv'):\n",
    "    # Load the saved augmented data if available\n",
    "    df_neg_2 = pd.read_csv('data/df_neg_2.csv')\n",
    "else:\n",
    "    # How many positive tweets do we want to augment?\n",
    "    n = 262000\n",
    "    # Apply antonym augmentation to positive tweets (to help balance negative tweets count)\n",
    "    # Note that not all positive tweets will become negative tweets even after augmentation\n",
    "    df_neg_2 = df[ label_equal(np.array([1, 0, 0]), df) ].head(n)\n",
    "    df_neg_2['text'] = df_neg_2['text'].swifter.apply(lambda x: preproc_augment(x, synonym = False))\n",
    "    # Reapply VADER's sentiment analysis and mark the augmented data\n",
    "    df_neg_2['label'] = df_neg_2['text'].swifter.apply(vader_sentiment)\n",
    "    df_neg_2['augmented'] = True\n",
    "\n",
    "    # Backup the unfiltered antonymized tweets\n",
    "    print('Before filter:', len(df_neg_2))\n",
    "    df_neg_2.to_csv('data/df_neg_2a.csv', index = False)\n",
    "    # Take only the negative tweets\n",
    "    df_neg_2 = df_neg_2 [ label_equal(np.array[0, 0, 1], df_neg_2) ]\n",
    "\n",
    "print('After filter:', len(df_neg_2))\n",
    "df_neg_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From 262000 positive tweets, only 30208 ends up as negative tweets after applying the antonym augmentation. Combined with the previous synonym augmentation, we only end up with 264k new negative tweets (time needed: ~55 minutes)\n",
    "- **Conclusion:** word based augmentation is slow and doesn't guarantee better class distribution, especially in the case of data balancing (oversampling). Next time, we should try vector level augmentation instead (SMOTE, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_arr(value: str, dtype = None):\n",
    "    if type(value) == float and math.isnan(value):\n",
    "        return pd.NA\n",
    "    else:\n",
    "        # Take everything between square brackets (list)\n",
    "        value = re.sub(r'\\[([^]]+)\\]', r'\\1', value)\n",
    "        # Convert space separated string to Numpy's array\n",
    "        value = [ int(i) for i in value.split() ]\n",
    "        return np.array(value, dtype)\n",
    "\n",
    "def fix_data_type(df):\n",
    "    df['label'] = df['label'].apply(lambda x: str_to_arr(x) if type(x) == str else int(x))\n",
    "    df['response_tweet_id'] = df['response_tweet_id'].apply(lambda x: str_to_arr(x, np.int64))\n",
    "\n",
    "    try:\n",
    "        # https://strftime.org/\n",
    "        df['created_at'] = pd.to_datetime(df['created_at'], format = '%Y-%m-%d %H:%M:%S+00:00')\n",
    "    except ValueError:\n",
    "        df['created_at'] = pd.to_datetime(df['created_at'], format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Convert float to Pandas' Int64 (support nan)\n",
    "    # Pandas' Int64 array will use \"pd.NA\" rather than \"np.nan\"\n",
    "    # https://pandas.pydata.org/docs/user_guide/integer_na.html\n",
    "    cols = ['tweet_id', 'in_response_to_tweet_id']\n",
    "    df[cols] = df[cols].astype('Int64')\n",
    "\n",
    "    return df\n",
    "\n",
    "# ======================\n",
    "\n",
    "if not os.path.isfile('data/df_neg_1.csv'):\n",
    "    # Save the augmented dataframe if it hasn't been saved yet\n",
    "    df_neg_1.to_csv('data/df_neg_1.csv', index = False)\n",
    "    df_neg_2.to_csv('data/df_neg_2.csv', index = False)\n",
    "else:\n",
    "    # If we load the saved augmented dataframe, fix the data type first\n",
    "    df_neg_1 = fix_data_type(df_neg_1)\n",
    "    df_neg_2 = fix_data_type(df_neg_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backup the original data as `df_orig`, then decide whether to combine the augmented data with the original one or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2939050\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "      <th>label</th>\n",
       "      <th>augmented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 22:10:47+00:00</td>\n",
       "      <td>I understand. I would like to assist you. We ...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:11:45+00:00</td>\n",
       "      <td>and how do you propose we do that</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:08:27+00:00</td>\n",
       "      <td>I have sent several private messages and no o...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 21:54:49+00:00</td>\n",
       "      <td>Please send us a Private Message so that we c...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 21:49:35+00:00</td>\n",
       "      <td>I did.</td>\n",
       "      <td>[4]</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                 created_at  \\\n",
       "0         1  sprintcare    False  2017-10-31 22:10:47+00:00   \n",
       "1         2      115712     True  2017-10-31 22:11:45+00:00   \n",
       "2         3      115712     True  2017-10-31 22:08:27+00:00   \n",
       "3         4  sprintcare    False  2017-10-31 21:54:49+00:00   \n",
       "4         5      115712     True  2017-10-31 21:49:35+00:00   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0   I understand. I would like to assist you. We ...               [2]   \n",
       "1                  and how do you propose we do that              <NA>   \n",
       "2   I have sent several private messages and no o...               [1]   \n",
       "3   Please send us a Private Message so that we c...               [3]   \n",
       "4                                             I did.               [4]   \n",
       "\n",
       "   in_response_to_tweet_id  label  augmented  \n",
       "0                        3      0      False  \n",
       "1                        1      1      False  \n",
       "2                        4      1      False  \n",
       "3                        5      1      False  \n",
       "4                        6      1      False  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the augmented tweets with the original tweets\n",
    "df = pd.concat([df_orig, df_neg_1, df_neg_2], ignore_index = True)\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the tweets distribution after augmentation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(\n",
    "    go.Bar(\n",
    "        x = ['Positive', 'Neutral', 'Negative'],\n",
    "        # Binary label\n",
    "        y = df['label'].value_counts().sort_index()\n",
    "        # One hot label\n",
    "        # y = np.sum(df['label'].values)\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(title_text = 'Tweet Sentiment Distribution')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweets are still not balanced, even though the number of negative tweets has now doubled (from 234k to 498k). To make the data more balanced, we can apply undersampling on the neutral tweets. Usually applying undersampling is discouraged since we may lose important features of the data. However, since the data we have is already too big (2.9 million tweets) and we don't use it for a research project, I think it doesn't hurt to apply undersampling, it will also make the training process a lot faster.\n",
    "\n",
    "There are at least 3 types of undersampling:\n",
    "- Stratified (proportionate) undersampling: Take fraction of data from each class proportionally (e.g. 1% of data from each class)\n",
    "- Disproportionate undersampling: Take exactly the same amount of data from each class (e.g. 10000 data from each class)\n",
    "- Random undersampling: Take N amount of data without grouping the data by class distribution (totally random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pseudo-random seed\n",
    "seed = 1337\n",
    "# Apply undersampling, or not\n",
    "use_undersampling = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    58.177859\n",
      "0    24.869855\n",
      "2    16.952286\n",
      "Name: proportion, dtype: float64\n",
      "Total rows: 88171\n"
     ]
    }
   ],
   "source": [
    "if use_undersampling:\n",
    "    # Apply stratified undersampling on the dataframe\n",
    "    df = df.groupby('label', group_keys = False).apply(lambda x: x.sample(frac = 0.03, random_state = seed))\n",
    "\n",
    "    # Apply disproportionate undersampling on the dataframe\n",
    "    # df = df.groupby('label', group_keys = False).apply(lambda x: x.sample(n = 30000, random_state = seed))\n",
    "\n",
    "    # The \"sample\" function is not truly random (always have the same class distribution)\n",
    "    # \"head\" or \"tail\" can be used instead (will be trully random assuming the data is shuffled)\n",
    "    # df = df.head(n = 90000)\n",
    "\n",
    "print(df['label'].value_counts(normalize = True).mul(100))\n",
    "print('Total rows:', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying oversampling/undersampling, ideally we should test whether the model loss curve is similar or not (compared to the unchanged dataset), see [this article](https://freedium.cfd/https://towardsdatascience.com/your-dataset-is-imbalanced-do-nothing-abf6a0049813) for some details. If the curve changed drastically, it means that we may have lose important features of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Basic Text Preprocessing (2)**\n",
    "We need to apply additional preprocessing to reduce LSTM model complexity. Since tokenization will be applied later, things like punctuations, mixed string case, and other unexpected elements can be interpreted differently by the model if not normalized beforehand (e.g. `I'm`, `I am`, and `i am` are all different words).\n",
    "\n",
    "However, if applied earlier, it can negatively affect VADER's accuracy, because VADER can also detect sentiment based on many factors, including string case and punctuations (`IT WAS SO FRUSTATING!!!`, etc).\n",
    "\n",
    "We need to:\n",
    "- Remove punctuations\n",
    "- Convert text to lowercase\n",
    "- Remove single character word\n",
    "- Remove stopwords - **NOT USED**\n",
    "- Apply stemming/lemmatization - **NOT USED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'you', 'his', \"she's\", 'once', 'they', 'from', 'him', 'again', 'under', 'but', 'then', 'been', \"doesn't\", 'itself', 't', 'more', 'yourself', 'off', \"didn't\", 'on', 'and', \"should've\", \"needn't\", 'ourselves', 'such', 'each', 'd', \"hasn't\", 'she', 'how', 'doesn', 'why', 'above', 'between', \"weren't\", 'needn', \"shouldn't\", 'is', 'nor', \"haven't\", 'didn', 'in', 'by', 'does', 've', \"shan't\", 'mightn', 'them', 'ma', 'weren', 'down', 'where', 'y', 'after', 'mustn', 'there', 'my', 'doing', 'were', 'aren', \"hadn't\", 'about', 'our', 'to', 'into', 'which', 'your', 'have', 'against', \"mightn't\", 'shouldn', 'wouldn', 'he', 'shan', 'being', 'too', 'haven', 'i', \"isn't\", 'those', 'through', 'o', 'who', 'so', 'having', 'yourselves', 'can', 'isn', 'her', 'own', 'same', \"don't\", 'further', 'when', 'herself', 's', 'during', 'theirs', 'are', 'm', 'for', 'here', 'few', \"aren't\", 'did', \"you'd\", \"couldn't\", 'couldn', 'hasn', \"you'll\", 'before', \"wasn't\", \"wouldn't\", 'myself', 'will', 'or', 'had', 'up', 'll', 'was', 'their', 'because', 'the', 'hadn', 'themselves', 'other', 'don', 'its', 'ain', 'of', 'that', 'most', 'very', 'himself', 'if', 'now', 'won', 'while', 'should', 'am', 'has', 'these', 'do', 'an', \"mustn't\", 'hers', 'whom', 'me', 'only', 'this', 'out', 'over', 'we', \"you're\", 'a', \"it's\", 'any', 'all', 'just', 'wasn', \"you've\", 'as', 'ours', \"that'll\", 'with', 'at', 'some', 'than', 'both', 'no', 'it', \"won't\", 'not', 're', 'yours', 'be', 'below', 'until', 'what'}\n"
     ]
    }
   ],
   "source": [
    "# Stopwords we used when we did tweet augmentation earlier\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Not good... I got the \"Access Denied\" error when opening the application üò§ \n",
      "\n",
      "Porter: not good got the access deni error when open the applic üò§\n",
      "Snowball: not good got the access deni error when open the applic üò§\n",
      "WordNet: not good got the access denied error when opening the application üò§\n",
      "Stopwords: good got access denied error opening application üò§\n",
      "Default: not good got the access denied error when opening the application üò§\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# =================================\n",
    "# Stemmer or lemmatizer\n",
    "# =================================\n",
    "\n",
    "# Stemmer\n",
    "porter = SnowballStemmer('porter')\n",
    "snowball = SnowballStemmer('english')\n",
    "\n",
    "# Lemmatizer\n",
    "try:\n",
    "    wordnet = WordNetLemmatizer()\n",
    "except:\n",
    "    nltk.download('wordnet')\n",
    "    wordnet = WordNetLemmatizer()\n",
    "\n",
    "# =================================\n",
    "# LSTM preprocessing function\n",
    "# =================================\n",
    "\n",
    "def preproc_for_model(value: str, stemmer = None, stop_words = None):\n",
    "    # Remove punctuations (and emoticons)\n",
    "    value = re.sub(f'[{string.punctuation}]', ' ', value)\n",
    "    # Lowercase, but ignore unicode characters\n",
    "    value = value.casefold()\n",
    "    # Remove 1-character word\n",
    "    value = re.sub(r'\\b[a-zA-Z]\\b', '', value)\n",
    "    # Replace multiple spaces with a single space\n",
    "    value = re.sub(r'\\s+', ' ', value)\n",
    "\n",
    "    if stemmer or stop_words:\n",
    "        # Split sentence as words (tokenization)\n",
    "        word_token = value.split()\n",
    "\n",
    "        if stop_words:\n",
    "            # Remove stop words (must be prioritized before stemmer)\n",
    "            word_token = [ word for word in word_token if word not in stop_words ]\n",
    "        if stemmer:\n",
    "            # Stem/lemmatize words\n",
    "            try: word_token = [ stemmer.lemmatize(word) for word in word_token ]\n",
    "            except: word_token = [ stemmer.stem(word) for word in word_token ]\n",
    "\n",
    "        # Join the tokenized words again\n",
    "        # A bit inefficient if we use it with TextVectorization layer\n",
    "        value = ' '.join(word_token)\n",
    "    \n",
    "    return value\n",
    "\n",
    "def preproc_all(value: str, stemmer = None):\n",
    "    # Remove URLs, mentions, hashtags, etc\n",
    "    value = preproc_useless_info(value)\n",
    "    # Remove punctuations, stopwords, etc\n",
    "    value = preproc_for_model(value, stemmer)\n",
    "    return value\n",
    "\n",
    "# =================================\n",
    "# Test the preprocessing function\n",
    "# =================================\n",
    "\n",
    "text = 'Not good... I got the \"Access Denied\" error when opening the application üò§'\n",
    "print('Original:', text, '\\n')\n",
    "\n",
    "print('Porter:', preproc_for_model(text, porter))\n",
    "print('Snowball:', preproc_for_model(text, snowball))\n",
    "print('WordNet:', preproc_for_model(text, wordnet))\n",
    "print('Stopwords:', preproc_for_model(text, None, stop_words))\n",
    "print('Default:', preproc_for_model(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see, the stemmer and lemmatizer didn't give good enough results, and similar words can also have slightly different meaning (like VADER scoring system). So, we can just skip it if we want to follow VADER's approach.\n",
    "\n",
    "- As for stopwords removal, it doesn't give a good result either. By default, NLTK's stopwords will remove important features for sentiment analysis, such as `not`, `very`, `most`, etc, while the ones we need to remove are mostly conjunction/transition words (e.g. `although`, `with`, `that`). Unless we want to build our own stopwords list, then it's better to just skip it as it brings more harm than good.\n",
    "\n",
    "The preprocessing will be done right before we apply tokenization/vectorization, so there's no need to apply it right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.swifter.apply(preproc_for_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LSTM Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Split Training and Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "def label_transformer(label_list: pd.Series, class_mode = 'binary'):\n",
    "    if label_list.dtype == np.int64: # Already in binary\n",
    "        if class_mode == 'one_hot':\n",
    "            # Change array shape from [0 1 2 ...] to [[0] [1] [2] ...]\n",
    "            label_list = np.reshape(label_list.values, (-1, 1))\n",
    "            return OneHotEncoder(sparse = False).fit_transform(label_list)\n",
    "        elif class_mode == 'binary':\n",
    "            return label_list\n",
    "    else: # Already one hot encoded\n",
    "        # Fix nested array data type from (object,int) to (int,int)\n",
    "        label_list =  np.stack(label_list.values)\n",
    "        if class_mode == 'one_hot':\n",
    "            return label_list\n",
    "        elif class_mode == 'binary':\n",
    "            return np.argmax(label_list, axis = 1)\n",
    "\n",
    "# Label type (use one hot or binary)\n",
    "# It depends on the model you want to design (sparse or categorical)\n",
    "# Sparse model return probability, while categorical model return label\n",
    "label = label_transformer(df['label'], 'binary')\n",
    "\n",
    "# X is the data (text), while Y is the label (class)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df['text'],\n",
    "    label,\n",
    "    test_size = 0.2,\n",
    "    # Distribute the data evenly\n",
    "    stratify = label,\n",
    "    # Seed for reproducibility\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# Balance class weight to workaround imbalanced data\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight = 'balanced',\n",
    "    classes = np.unique(y_train),\n",
    "    y = y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.3403260745639038, 1: 0.5729603275173019, 2: 1.9662150861348051}\n"
     ]
    }
   ],
   "source": [
    "class_weights = dict(zip(np.unique(y_train), class_weights))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70536\n",
      "label\n",
      "1    58.177385\n",
      "0    24.869570\n",
      "2    16.953045\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(y_train.value_counts(normalize = True).mul(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17635\n",
      "label\n",
      "1    58.179756\n",
      "0    24.870995\n",
      "2    16.949249\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test))\n",
    "print(y_test.value_counts(normalize = True).mul(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Defining Layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The terms `vector` and `array` are interchangeable.\n",
    "\n",
    "- Tokenization: split sentence to words\n",
    "- Vocabulary: list of known words (usually after tokenization process)\n",
    "- Vectorization: transform the words to other form (one hot encoding, index based, TF-IDF, etc) based on a vocabulary\n",
    "\n",
    "Note that when defining vocabulary size, 1-2 spaces will usually be reserved for OOV (out-of-vocabulary) and/or empty word. There are 2 at least to ways to do tokenization and vectorization:\n",
    "- `Tokenizer` (function) will reserve 1 space\n",
    "- `TextVectorization` (layer) will reserve 2 spaces\n",
    "\n",
    "So you may want to add +1/+2 vocabulary size depending on what you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# Max words/features/vocabulary to save (most frequent words only)\n",
    "# For comparison, the latest VADER (v3.3.2) has 11090 vocabulary (combined with emojis)\n",
    "# We should at least match that if we want to compare it\n",
    "max_vocab = 12000\n",
    "# Max words for each sentence\n",
    "# Sentence longer than that will be truncated\n",
    "max_len = 50\n",
    "# Indicator if you want to use Tokenizer on the model\n",
    "# Otherwise, TextVectorization layer will be used\n",
    "use_tokenizer = True\n",
    "# Set seed for reproducibility\n",
    "keras.utils.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to convert words to vectors, you can either use:\n",
    "- One Hot Encoding\n",
    "- Count\n",
    "- TF-IDF\n",
    "- Word Index\n",
    "\n",
    "The problem with one hot encoding is that each array size can be very big (since it's a binary array). For example, if there are 1000 rows (tweets) with 5000 vocab size, then it would produce 1000 arrays, each with 5000 length, which can be worse depending on the batch and data size (2.9 million tweets?).\n",
    "\n",
    "That's why when using `Tokenizer`, `text_to_sequences` (int/word index based array) is preferred rather than `texts_to_matrix` (TF-IDF, one hot encoding, count, etc) nowadays.\n",
    "\n",
    "We can also use `TextVectorization`, which does the same as `Tokenizer`, but can be integrated to the model directly (as preprocessing layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf62967e23fb4af89e2256d13938a50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/70536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea68027f57d4ccdaf65ff63cbf4820a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/17635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['[UNK]', 'to', 'the', 'you', 'and', 'we', 'for', 'your', 'this', 'it', 'is', 'can', 'on', 'my', 'in', 'with', 'us', 'of', 'have', 'please', 'that', 'dm', 'be', 'so', 'me', 'not', 'are', 'help', 'if', 'our', 'at', 'hi', 'no', 'but', 'what', 'out', 'there', 'get', 'here', 'sorry', 'thanks', 'do', 're', 'was', 'from', 'will', '2', 'as', 'up', 'just']\n",
      "Vocabulary size: 34209\n",
      "Output vector: [[ 32  37 156 ...   0   0   0]\n",
      " [ 21 527  62 ...   0   0   0]\n",
      " [346 151  13 ...   0   0   0]\n",
      " ...\n",
      " [ 15   3 778 ...   0   0   0]\n",
      " [107  10 109 ...   0   0   0]\n",
      " [ 10  67 228 ...   0   0   0]]\n",
      "Output vector size: (70536, 50)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "if use_tokenizer:\n",
    "    # Apply preprocessing before tokenization (training only or both)\n",
    "    x_train = x_train.swifter.apply(preproc_for_model)\n",
    "    x_test = x_test.swifter.apply(preproc_for_model)\n",
    "\n",
    "    # Add 1 vocabulary space for OOV (out-of-vocabulary) word\n",
    "    max_vocab += 1\n",
    "\n",
    "    # There's no empty token for one hot encoding (only OOV)\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "    tokenizer = Tokenizer(num_words = max_vocab, oov_token='[UNK]')\n",
    "\n",
    "    # Build vocabulary based on texts (only the most frequent words will be saved)\n",
    "    # Will generate word index (vocabulary), word index must match between training and test data\n",
    "    tokenizer.fit_on_texts(x_train)\n",
    "    # \"text_to_sequences\" will transform words to its index (like int mode in TextVectorization layer)\n",
    "    # To transform words to other forms (TF-IDF, etc) use \"texts_to_matrix\" instead\n",
    "    x_train = tokenizer.texts_to_sequences(x_train)\n",
    "\n",
    "    # Don't use \"fit_on_texts\" on test data, because the word index (vocabulary) will be regenerated again\n",
    "    # If the vocabulary between training and test data doesn't match, the model will have a bad accuracy\n",
    "    # We only need to use \"texts_to_sequences\", any unknown word will be converted to OOV (index 1)\n",
    "    x_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "    # Make sure all arrays have the same length (will follow the longest sentence if maxlen is not specified)\n",
    "    # TextVectorization will use post-padding by default (uncustomizable), so we apply the same for reproducibility\n",
    "    # Setting max length is optional, but by setting it, we can use a standardized model input shape\n",
    "    # The length should be less/equal than the longest sentence, setting more will only increase memory usage\n",
    "    x_train = pad_sequences(x_train, padding = 'post', truncating = 'post', maxlen = max_len) \n",
    "    x_test = pad_sequences(x_test, padding = 'post', truncating = 'post', maxlen = max_len)\n",
    "\n",
    "    print('Vocabulary:', list(tokenizer.word_index)[:50])\n",
    "    print('Vocabulary size:', len(tokenizer.word_index))\n",
    "    print('Output vector:', x_train)\n",
    "    print('Output vector size:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Encoding to interpret the text (to be passed to the model)\n",
    "# Some encodings can remove \"unique\" characters such as emojis (e.g. latin-1)\n",
    "encoding = 'utf-8'\n",
    "\n",
    "# This is a hacky function to automate text preprocessing as part of the model\n",
    "# There is no need to apply preprocessing separately (unless you use Tokenizer)\n",
    "def custom_standardization(input_data):\n",
    "    # Skip if the layer is just initialized (no data yet)\n",
    "    if tf.is_symbolic_tensor(input_data): return input_data\n",
    "\n",
    "    # Convert tensor to Numpy's array (for easier manipulation)\n",
    "    # The array will have byte as it's data type\n",
    "    input_data = input_data.numpy()\n",
    "\n",
    "    \"\"\" # TODO Apply vectorization\n",
    "    for i in range(len(input_data)):\n",
    "        # Apply preprocessing\n",
    "        # Convect byte to string and vice versa\n",
    "        input_data[i] = bytes(\n",
    "            preproc_for_model(input_data[i].decode('utf-8')),\n",
    "            'utf-8'\n",
    "        ) \"\"\"\n",
    "\n",
    "    __preproc_for_model = np.vectorize(\n",
    "        lambda sentence: bytes(\n",
    "            # Please change to \"preproc_all\" instead for unseen data\n",
    "            # Since we did sentiment analysis earlier, \"preproc_useless_info\" is already applied\n",
    "            # So all that's left is to apply \"preproc_for_model\" (remove punctuations, etc)\n",
    "            preproc_for_model(sentence.decode(encoding)),\n",
    "            encoding\n",
    "        ),\n",
    "        cache = True\n",
    "    )\n",
    "\n",
    "    # Appply preprocessing and convert back Numpy's byte array to tensor\n",
    "    input_data = __preproc_for_model(input_data)\n",
    "    input_data = tf.convert_to_tensor(input_data)\n",
    "\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['', '[UNK]', 'is', 'the', 'service', 'not', 'The', 'ü§©', 'you', 'so-so,', 'so', 'rude!!!', 'provided', 'guy', 'good', 'especially', 'either', 'customer', 'contacted', 'company', 'but', 'best,', 'bad', 'at', 'all,', 'Your', 'NOT', 'I', 'GOOD']\n",
      "Vocabulary size: 29\n",
      "Output vector: tf.Tensor(\n",
      "[[ 1 19  2  3  1 15  3  4  8 12  7  0  0]\n",
      " [ 3 17  4  2 10 10  5 14 20  5 22 16  0]\n",
      " [ 3  4  2  5 14 23  1  3 13 18  2 10  1]], shape=(3, 13), dtype=int64)"
     ]
    }
   ],
   "source": [
    "# 2 spaces will be reserved to for empty word and OOV (out-of-vocabulary)\n",
    "# Unlike Tokenizer which only take 1 vocabulary space (OOV only)\n",
    "if not use_tokenizer: max_vocab += 2\n",
    "\n",
    "# Based on the docs, Tokenizer is already deprecated, use TextVectorization instead\n",
    "# TextVectorization can integrate preprocessing (standardization) function such as part of the layer\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization\n",
    "# https://www.tensorflow.org/guide/keras/preprocessing_layers\n",
    "vectorization_layer = keras.layers.TextVectorization(\n",
    "    # Low vocabulary may affect accuracy, while high vocabulary can affect complexity & memory usage\n",
    "    max_tokens = max_vocab,\n",
    "    # \"lower_and_strip_punctuation\", \"lower\", \"strip_punctuation\", None, or custom function\n",
    "    # FIXME Currently, the custom function won't affect the vocabulary list (lowercase won't be applied, etc)\n",
    "    standardize = custom_standardization,\n",
    "    # Use 2 or higher to possibly detect idioms, negation, slang words, etc\n",
    "    # None means no N-grams when splitting words aka 1-gram\n",
    "    ngrams = None,\n",
    "    # Either \"int\" (index array), \"multi_hot\" (0/1 array), \"count\" (count array), or \"tf_idf\" (ratio array)\n",
    "    # Use \"int\" to minimize array size, but may be a burden for computation later (e.g. multiplication)\n",
    "    output_mode = 'int',\n",
    "    # Apply post-padding (all zeros) to each array up to max tokens, ignored if using \"int\" mode\n",
    "    # Warning: will consume a large amount of memory if the vocabulary list is huge\n",
    "    # Regardless it's used or not, all arrays will always have uniform length\n",
    "    pad_to_max_tokens = False,\n",
    "    # Limit or set array size for each sample, only applies to \"int\" mode\n",
    "    # Useful to further reduce memory usage and limit garbage words, but can affect accuracy\n",
    "    # If the array size is less than the specified length, post-padding will be applied\n",
    "    # And if it is bigger than embedding input size, truncation will be applied\n",
    "    output_sequence_length = False,\n",
    "    # Encoding to interpret the text\n",
    "    # Some encodings can remove \"unique\" characters such as emojis (e.g. latin-1)\n",
    "    encoding = encoding,\n",
    "    # Layer name (optional)\n",
    "    name = 'text_vectorization'\n",
    ")\n",
    "\n",
    "text = [\n",
    "    'Your company is the best, especially the service you provided ü§©',\n",
    "    'The customer service is so-so, not good but not bad either',\n",
    "    'The service is NOT GOOD at all, the guy I contacted is so rude!!!'\n",
    "]\n",
    "\n",
    "# Experiment with the hyperparameters above, then test the result\n",
    "vectorization_layer.adapt(text)\n",
    "\n",
    "print('Vocabulary:', vectorization_layer.get_vocabulary()[:50])\n",
    "print('Vocabulary size:', vectorization_layer.vocabulary_size())\n",
    "print('Output vector:', vectorization_layer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Currently, the custom standardization function won't affect the vocabulary list (lowercase won't be applied, etc). I have filled an issue here: [#62653](https://github.com/tensorflow/tensorflow/issues/62653). In the meantime, we will use `Tokenizer` function instead of the `TextVectorization` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_tokenizer:\n",
    "    # Rebuild the vocabulary using the whole training data (no need to adapt the test data)\n",
    "    # If the vocabulary between training and test data is different, the model will be confused\n",
    "    vectorization_layer.adapt(x_train)\n",
    "    print(vectorization_layer.get_vocabulary()[:50])\n",
    "    print(vectorization_layer.vocabulary_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda (Lambda)             (None, 50)                0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 50, 50)            600050    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 50, 32)            1632      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 25, 32)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 64)                16640     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 635093 (2.42 MB)\n",
      "Trainable params: 635093 (2.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Reset Keras layers/models to their initial state\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Set model input shape\n",
    "if use_tokenizer:\n",
    "    # Sentences already vectorized\n",
    "    input_shape = (max_len,)\n",
    "    input_dtype = tf.int64\n",
    "else:\n",
    "    # Still just sentences\n",
    "    input_shape = (1,)\n",
    "    input_dtype = tf.string\n",
    "\n",
    "# https://keras.io/examples/nlp/text_classification_from_scratch\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape = input_shape, dtype = input_dtype),\n",
    "\n",
    "    # TODO Make a custom layer subclass instead of using lambda\n",
    "    # keras.layers.Lambda(custom_standardization),\n",
    "    keras.layers.Lambda(lambda x: x if use_tokenizer else vectorization_layer(x)),\n",
    "    # vectorization_layer,\n",
    "\n",
    "    # Truncation may be applied if the array size is longer than input length\n",
    "    keras.layers.Embedding(input_dim = max_vocab, output_dim = 50, input_length = max_len),\n",
    "\n",
    "    keras.layers.Conv1D(filters = 32, kernel_size = 1, padding = 'same', activation = 'relu'),\n",
    "    keras.layers.MaxPooling1D(pool_size = 2),\n",
    "\n",
    "    # If the result is still bad with dropout we can also use regularizer or batch normalization\n",
    "    # https://stats.stackexchange.com/questions/383310/difference-between-kernel-bias-and-activity-regularizers\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/L1L2\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(units = 32, kernel_regularizer = 'l1_l2')),\n",
    "    keras.layers.Dropout(rate = 0.4),\n",
    "\n",
    "    keras.layers.Dense(units = 128, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 64, activation = 'relu'),\n",
    "\n",
    "    # Positive, neutral, or negative sentiment (3 classes)\n",
    "    keras.layers.Dense(units = 3, activation = 'softmax'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Begin Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.8444 - acc: 0.7408\n",
      "Epoch 1: val_acc improved from -inf to 0.82104, saving model to misc\\model.tf\n",
      "INFO:tensorflow:Assets written to: misc\\model.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: misc\\model.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 127s 55ms/step - loss: 0.8444 - acc: 0.7408 - val_loss: 0.4823 - val_acc: 0.8210\n",
      "Epoch 2/50\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3980 - acc: 0.8398\n",
      "Epoch 2: val_acc improved from 0.82104 to 0.82217, saving model to misc\\model.tf\n",
      "INFO:tensorflow:Assets written to: misc\\model.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: misc\\model.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 238s 108ms/step - loss: 0.3980 - acc: 0.8398 - val_loss: 0.4722 - val_acc: 0.8222\n",
      "Epoch 3/50\n",
      "2204/2205 [============================>.] - ETA: 0s - loss: 0.3600 - acc: 0.8591\n",
      "Epoch 3: val_acc improved from 0.82217 to 0.85143, saving model to misc\\model.tf\n",
      "INFO:tensorflow:Assets written to: misc\\model.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: misc\\model.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 164s 74ms/step - loss: 0.3599 - acc: 0.8591 - val_loss: 0.4200 - val_acc: 0.8514\n",
      "Epoch 4/50\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3368 - acc: 0.8688\n",
      "Epoch 4: val_acc improved from 0.85143 to 0.85620, saving model to misc\\model.tf\n",
      "INFO:tensorflow:Assets written to: misc\\model.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: misc\\model.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 167s 76ms/step - loss: 0.3368 - acc: 0.8688 - val_loss: 0.4046 - val_acc: 0.8562\n",
      "Epoch 5/50\n",
      "2204/2205 [============================>.] - ETA: 0s - loss: 0.3207 - acc: 0.8764\n",
      "Epoch 5: val_acc improved from 0.85620 to 0.86243, saving model to misc\\model.tf\n",
      "INFO:tensorflow:Assets written to: misc\\model.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: misc\\model.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 160s 73ms/step - loss: 0.3207 - acc: 0.8764 - val_loss: 0.3940 - val_acc: 0.8624\n",
      "Epoch 6/50\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3062 - acc: 0.8825\n",
      "Epoch 6: val_acc did not improve from 0.86243\n",
      "2205/2205 [==============================] - 159s 72ms/step - loss: 0.3062 - acc: 0.8825 - val_loss: 0.4170 - val_acc: 0.8517\n",
      "Epoch 7/50\n",
      "2204/2205 [============================>.] - ETA: 0s - loss: 0.2945 - acc: 0.8876\n",
      "Epoch 7: val_acc improved from 0.86243 to 0.86799, saving model to misc\\model.tf\n",
      "INFO:tensorflow:Assets written to: misc\\model.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: misc\\model.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 176s 80ms/step - loss: 0.2945 - acc: 0.8876 - val_loss: 0.3858 - val_acc: 0.8680\n",
      "Epoch 8/50\n",
      "2204/2205 [============================>.] - ETA: 0s - loss: 0.2847 - acc: 0.8922\n",
      "Epoch 8: val_acc did not improve from 0.86799\n",
      "2205/2205 [==============================] - 140s 63ms/step - loss: 0.2848 - acc: 0.8922 - val_loss: 0.4016 - val_acc: 0.8577\n",
      "Epoch 9/50\n",
      "2204/2205 [============================>.] - ETA: 0s - loss: 0.2747 - acc: 0.8956\n",
      "Epoch 9: val_acc did not improve from 0.86799\n",
      "2205/2205 [==============================] - 140s 63ms/step - loss: 0.2748 - acc: 0.8956 - val_loss: 0.3958 - val_acc: 0.8659\n",
      "Epoch 10/50\n",
      "2204/2205 [============================>.] - ETA: 0s - loss: 0.2661 - acc: 0.8983\n",
      "Epoch 10: val_acc did not improve from 0.86799\n",
      "2205/2205 [==============================] - 146s 66ms/step - loss: 0.2661 - acc: 0.8983 - val_loss: 0.4133 - val_acc: 0.8555\n",
      "Epoch 11/50\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2600 - acc: 0.9014\n",
      "Epoch 11: val_acc did not improve from 0.86799\n",
      "2205/2205 [==============================] - 158s 72ms/step - loss: 0.2600 - acc: 0.9014 - val_loss: 0.4071 - val_acc: 0.8597\n",
      "Epoch 12/50\n",
      "2204/2205 [============================>.] - ETA: 0s - loss: 0.2518 - acc: 0.9066\n",
      "Epoch 12: val_acc did not improve from 0.86799\n",
      "2205/2205 [==============================] - 151s 69ms/step - loss: 0.2518 - acc: 0.9066 - val_loss: 0.4477 - val_acc: 0.8590\n",
      "Epoch 13/50\n",
      "2204/2205 [============================>.] - ETA: 0s - loss: 0.2457 - acc: 0.9090\n",
      "Epoch 13: val_acc did not improve from 0.86799\n",
      "2205/2205 [==============================] - 143s 65ms/step - loss: 0.2457 - acc: 0.9090 - val_loss: 0.4600 - val_acc: 0.8514\n",
      "Epoch 14/50\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2413 - acc: 0.9103\n",
      "Epoch 14: val_acc did not improve from 0.86799\n",
      "2205/2205 [==============================] - 150s 68ms/step - loss: 0.2413 - acc: 0.9103 - val_loss: 0.4322 - val_acc: 0.8601\n",
      "Epoch 15/50\n",
      "2204/2205 [============================>.] - ETA: 0s - loss: 0.2373 - acc: 0.9125\n",
      "Epoch 15: val_acc did not improve from 0.86799\n",
      "2205/2205 [==============================] - 158s 72ms/step - loss: 0.2373 - acc: 0.9125 - val_loss: 0.4666 - val_acc: 0.8587\n",
      "Epoch 16/50\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2336 - acc: 0.9132\n",
      "Epoch 16: val_acc did not improve from 0.86799\n",
      "2205/2205 [==============================] - 173s 78ms/step - loss: 0.2336 - acc: 0.9132 - val_loss: 0.4676 - val_acc: 0.8543\n",
      "Epoch 17/50\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2293 - acc: 0.9156\n",
      "Epoch 17: val_acc did not improve from 0.86799\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "2205/2205 [==============================] - 158s 72ms/step - loss: 0.2293 - acc: 0.9156 - val_loss: 0.4650 - val_acc: 0.8550\n",
      "Epoch 17: early stopping\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Encoder to save model training history\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        # Some Numpy objects can't be encoded to json directly\n",
    "        if isinstance(obj, np.ndarray): return obj.tolist()\n",
    "        elif isinstance(obj, np.float32): return float(obj)\n",
    "        return super().default(self, obj)\n",
    "\n",
    "class StopAtAcc(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold: int):\n",
    "        super(StopAtAcc, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs: dict): \n",
    "        acc = logs.get('acc')\n",
    "        val_acc = logs.get('val_acc')\n",
    "\n",
    "        if acc >= self.threshold and val_acc >= self.threshold:\n",
    "            print(f'Epoch {epoch}: Reached {acc}% acc and {val_acc}% val_acc, stopping training')\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# =======================\n",
    "# Callback Function\n",
    "# =======================\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    # Don't save as keras if using the lambda layer\n",
    "    filepath = f'misc/model.tf',\n",
    "    monitor = 'val_acc',\n",
    "    mode = 'max',\n",
    "    save_best_only = True,\n",
    "    save_weights_only = False,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# Data must be shuffled if you want to use early stopping\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_acc',\n",
    "    min_delta = 0,\n",
    "    patience = 10,\n",
    "    mode = 'max',\n",
    "    restore_best_weights = True,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "stop_at = StopAtAcc(threshold = 90)\n",
    "\n",
    "# =======================\n",
    "# Training Model\n",
    "# =======================\n",
    "\n",
    "model.compile(\n",
    "    optimizer = keras.optimizers.AdamW(),\n",
    "    # Change loss depending on the label type (one hot/binary) and preferred output (probability/label)\n",
    "    # Sparse categorical = probability (e.g. [0.5 0.3 0.2]), categorical = label (e.g. [1 0 0])\n",
    "    # Use \"from_logits = False\" if the output is already normalized (e.g. using softmax)\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
    "    metrics = [ keras.metrics.SparseCategoricalAccuracy(name = 'acc') ]\n",
    ")\n",
    "\n",
    "# Try to load existing model first\n",
    "if os.path.isfile(f'misc/model.hist'):\n",
    "    is_training = False\n",
    "    model = keras.models.load_model(f'misc/model.tf')\n",
    "    with open(f'misc/model.hist') as hist:\n",
    "        history = json.load(hist)\n",
    "else:\n",
    "    is_training = True\n",
    "    # Train model from beginning\n",
    "    train = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs = 50,\n",
    "        validation_data = (x_test, y_test),\n",
    "        # Give more weight to class with less members\n",
    "        class_weight = class_weights,\n",
    "        # Model will be saved via checkpoint callbacks\n",
    "        callbacks = [ checkpoint, early_stopping, stop_at ],\n",
    "        verbose = 1\n",
    "    )\n",
    "    # Restore the best model from training (not always the last epoch)\n",
    "    model = keras.models.load_model(f'misc/model.tf')\n",
    "    # Save the model training history\n",
    "    with open(f'misc/model.hist', 'w') as hist:\n",
    "        json.dump(train.history, hist, cls = NumpyEncoder)\n",
    "    history = train.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that only model with the best `val_acc` will be saved and used, so the last epoch is just an indicator when the training stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = [ i for i in range(len(history['acc'])) ],\n",
    "        y = history['acc'],\n",
    "        name = 'Training Accuracy'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = [ i for i in range(len(history['acc'])) ],\n",
    "        y = history['val_acc'],\n",
    "        name = 'Validation Accuracy'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = [ i for i in range(len(history['acc'])) ],\n",
    "        y = history['loss'],\n",
    "        name = 'Training Loss'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = [ i for i in range(len(history['acc'])) ],\n",
    "        y = history['val_loss'],\n",
    "        name = 'Validation Loss'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_traces(mode = 'markers+lines')\n",
    "\n",
    "fig.update_layout(\n",
    "    # https://plotly.com/python/reference/layout/\n",
    "    title = { 'text': 'Model Training - Accuracy and Loss' },\n",
    "    # https://plotly.com/python/reference/layout/xaxis/\n",
    "    xaxis = { 'title': 'Epoch' },\n",
    "    # https://plotly.com/python/reference/layout/yaxis/\n",
    "    yaxis = { 'title': 'Accuracy/Loss' },\n",
    "    hovermode = 'x unified',\n",
    "    hoverlabel = { 'namelength': -1 }\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopped at epoch 17, but the best `val_acc` is at epoch 7, so model from epoch 7 will be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n",
      "Your customer service is awful\n",
      "LSTM -> [0.00861 0.38315 0.60824] Negative\n",
      "VADER -> Neutral \n",
      "\n",
      "Your customer service is awful üëø\n",
      "LSTM -> [0.00864 0.36702 0.62434] Negative\n",
      "VADER -> Negative \n",
      "\n",
      "Your customer service is ok\n",
      "LSTM -> [0.04808 0.9392  0.01271] Neutral\n",
      "VADER -> Neutral \n",
      "\n",
      "Your customer service is good\n",
      "LSTM -> [0.22569 0.65428 0.12003] Neutral\n",
      "VADER -> Neutral \n",
      "\n",
      "Your customer service is good üòä\n",
      "LSTM -> [0.98203 0.0172  0.00077] Positive\n",
      "VADER -> Positive \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_tweets(tweets: list):\n",
    "    if use_tokenizer:\n",
    "        # \"preproc_all\" = \"preproc_useless_info\" + \"preproc_for_model\"\n",
    "        tweets = [ preproc_all(i) for i in tweets ]\n",
    "\n",
    "        # Convert sentences to vector\n",
    "        tweets = tokenizer.texts_to_sequences(tweets)\n",
    "        tweets = pad_sequences(tweets, padding = 'post', truncating = 'post', maxlen = max_len)\n",
    "    else:\n",
    "        # \"preproc_for_model\" will be called by TextVectorization layer\n",
    "        tweets = [ preproc_useless_info(i) for i in tweets ]\n",
    "\n",
    "    return model.predict(tweets)\n",
    "\n",
    "def sparse_to_label(array: np.ndarray):\n",
    "    i = array.argmax()\n",
    "    return ['Positive', 'Neutral', 'Negative'][i]\n",
    "\n",
    "text = [\n",
    "    'Your customer service is awful',\n",
    "    'Your customer service is awful üëø',\n",
    "    'Your customer service is ok',\n",
    "    'Your customer service is good',\n",
    "    'Your customer service is good üòä'\n",
    "]\n",
    "\n",
    "with np.printoptions(precision = 5, suppress = True):\n",
    "    result = predict_tweets(text)\n",
    "    for i in range(len(result)):\n",
    "        print(f'{text[i]}')\n",
    "        print(f'LSTM -> {result[i]} {sparse_to_label(result[i])}')\n",
    "        print(f'VADER -> {vader_sentiment(text[i], \"label\")}', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the model's training accuracy is not good (less than 90% accuracy), it can still predict tweet sentiment correctly (using words and emojis). Therefore, I can conclude that this model is good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Changelog**\n",
    "\n",
    "- v1: Vectorization 5000 vocab size, embedding 32 output dims & 50 input length, Conv1D 32 filters, LSTM 32 units, dropout 0.4, dense 128, dense 64. Trained with 14 epoch resulting 60% accuracy using stratified undersampling 0.1 frac. Callback reduce LR 3, early stop 6\n",
    "- v2: Added max pool layer with pool size = 2 after Conv1D. Stopped manually at 7 epoch with accuracy 60%\n",
    "- v3: Switched to Bi-LSTM, increased vocab size to 20000. Stopped manually at 7 epoch with accuracy 60%. Sample size reduced to 0.01\n",
    "- v4: Bi-LSTM 64, batch size changed to 128 (the default is 32). Early stop at 23 epoch with 60% accuracy\n",
    "- v5: Using original data only (not combined with augmented data). Early stop at epoch 15 with 64% accuracy (slightly increased)\n",
    "- v6: Changed to disproportionate undersampling with N = 15000. Accuracy decreased to 50%, early stop at epoch 23.\n",
    "- v7: Switched to normal LSTM (not Bi-LSTM), with 9000 vocab size. Re-adapt text with training data (turns out vectorization layer doesn't automatically readapt when begining training). Accuracy improved to 81%, early stop at epoch 9. Graph overfit\n",
    "- v8: Stratified undersampling 0.02 (~58000 data). Reduce LR increased to 5 and early stop at 10, vocab size 12000. Still overfit training\n",
    "- v9: Stratified undersampling 0.03 (~88000 data). Manual stop at epoch 9, vocab size 12000. Still overfit\n",
    "- v10: Stratified undersampling 0.03 (~88000 data). Manual stop at epoch 9, vocab size 21000. Still overfit\n",
    "- v11: Disproportionate undersampling 30000 (90000 data). Manual stop at epoch 9, vocab size 21000. Still overfit\n",
    "- v12: Switch to Tokenizer instead of TextVectorization layer, since the preprocessing wasn't applied correctly. Used Bi-LSTM again. Early stop at epoch 13. Still overfit\n",
    "- v13: Reduced LSTM units to 32 for faster training. Used class weight balancing and stratified undersampling. Changed optimizer from Adam to AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Todo**\n",
    "\n",
    "- Inspect the output of each model layer like CNN\n",
    "- Reduce overfit without increasing sample size (switch embedding with TF-IDF? use pretrained embedding?) - [Reference](https://medium.com/@dcameronsteinke/tf-idf-vs-word-embedding-a-comparison-and-code-tutorial-5ba341379ab0)\n",
    "- EDA (the worst customer service, wordcloud, etc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
